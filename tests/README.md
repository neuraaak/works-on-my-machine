# Tests pour Works On My Machine

Ce rÃ©pertoire contient tous les tests pour le projet "Works On My Machine", organisÃ©s de maniÃ¨re structurÃ©e pour assurer la qualitÃ© et la fiabilitÃ© du code.

## ğŸ“ Structure des tests

```
tests/
â”œâ”€â”€ __init__.py                 # Package Python
â”œâ”€â”€ conftest.py                 # Configuration pytest et fixtures partagÃ©es
â”œâ”€â”€ unit/                       # Tests unitaires
â”‚   â”œâ”€â”€ test_security_validator.py    # Tests du validateur de sÃ©curitÃ©
â”‚   â”œâ”€â”€ test_secure_cli_manager.py    # Tests du gestionnaire CLI sÃ©curisÃ©
â”‚   â””â”€â”€ test_wom_cli.py               # Tests du CLI principal
â”œâ”€â”€ integration/                # Tests d'intÃ©gration
â”‚   â””â”€â”€ test_project_creation.py      # Tests de crÃ©ation de projets
â”œâ”€â”€ fixtures/                   # DonnÃ©es de test
â”‚   â”œâ”€â”€ sample_projects/        # Projets d'exemple
â”‚   â””â”€â”€ test_data/              # DonnÃ©es de test
â””â”€â”€ mocks/                      # Mocks et stubs
    â”œâ”€â”€ mock_cli_manager.py     # Mock du gestionnaire CLI
    â””â”€â”€ mock_system.py          # Mock des appels systÃ¨me
```

## ğŸ§ª Types de tests

### Tests unitaires (`tests/unit/`)

Les tests unitaires vÃ©rifient le comportement de composants individuels en isolation :

- **`test_security_validator.py`** : Tests du validateur de sÃ©curitÃ©
  - Validation des noms de projets
  - Validation des chemins de fichiers
  - Validation des commandes
  - Validation des opÃ©rations de fichiers
  - Validation des opÃ©rations de registre Windows

- **`test_secure_cli_manager.py`** : Tests du gestionnaire CLI sÃ©curisÃ©
  - ExÃ©cution de commandes sÃ©curisÃ©es
  - Gestion des erreurs et timeouts
  - Logique de retry
  - Validation de sÃ©curitÃ©
  - Mesure du temps d'exÃ©cution

- **`test_wom_cli.py`** : Tests du CLI principal
  - Commandes de crÃ©ation de projets
  - Commandes de linting
  - Commandes de vÃ©rification orthographique
  - Commandes systÃ¨me
  - Gestion des erreurs

### Tests d'intÃ©gration (`tests/integration/`)

Les tests d'intÃ©gration vÃ©rifient l'interaction entre plusieurs composants :

- **`test_project_creation.py`** : Tests de crÃ©ation de projets
  - Structure des projets Python
  - Structure des projets JavaScript
  - Configuration des projets
  - IntÃ©gration Git
  - Configuration VSCode
  - Workflows complets

## ğŸ·ï¸ Marqueurs de tests

Les tests utilisent des marqueurs pytest pour la catÃ©gorisation :

- `@pytest.mark.unit` : Tests unitaires
- `@pytest.mark.integration` : Tests d'intÃ©gration
- `@pytest.mark.security` : Tests de sÃ©curitÃ©
- `@pytest.mark.slow` : Tests lents
- `@pytest.mark.windows` : Tests spÃ©cifiques Windows
- `@pytest.mark.linux` : Tests spÃ©cifiques Linux
- `@pytest.mark.macos` : Tests spÃ©cifiques macOS

## ğŸš€ ExÃ©cution des tests

### Script de lancement

Utilisez le script `run_tests.py` Ã  la racine du projet :

```bash
# Tous les tests
python run_tests.py

# Tests unitaires uniquement
python run_tests.py --unit

# Tests d'intÃ©gration uniquement
python run_tests.py --integration

# Tests de sÃ©curitÃ© uniquement
python run_tests.py --security

# Tests avec couverture
python run_tests.py --coverage

# Tests rapides (sans tests lents)
python run_tests.py --fast

# Tests en parallÃ¨le
python run_tests.py --parallel

# Mode debug
python run_tests.py --debug

# VÃ©rifier les dÃ©pendances
python run_tests.py --check-deps

# Afficher le rÃ©sumÃ©
python run_tests.py --summary

# Test spÃ©cifique
python run_tests.py tests/unit/test_security_validator.py
```

### Commandes pytest directes

```bash
# Tous les tests
pytest tests/

# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration
pytest tests/integration/

# Tests avec marqueur spÃ©cifique
pytest -m security
pytest -m "not slow"

# Tests avec couverture
pytest --cov=shared --cov=languages --cov-report=html

# Tests en parallÃ¨le
pytest -n auto

# Tests avec plus de dÃ©tails
pytest -v --tb=long
```

## ğŸ”§ Configuration

### pytest.ini

Le fichier `pytest.ini` configure pytest avec :

- RÃ©pertoires de tests : `tests/`
- Marqueurs personnalisÃ©s
- Options par dÃ©faut (verbose, couleurs, etc.)
- Filtres d'avertissements

### conftest.py

Le fichier `conftest.py` dÃ©finit :

- **Fixtures partagÃ©es** : RÃ©pertoires temporaires, projets d'exemple
- **Mocks globaux** : CLI manager, subprocess, systÃ¨me de fichiers
- **Configuration automatique** : Marqueurs automatiques selon le nom de fichier
- **DonnÃ©es de test** : Noms de projets, chemins, commandes

## ğŸ“Š Couverture de code

La couverture de code est mesurÃ©e pour :

- `shared/` : Modules partagÃ©s (sÃ©curitÃ©, CLI, etc.)
- `languages/` : Modules spÃ©cifiques aux langages
- `wom_secure.py` : CLI principal sÃ©curisÃ©

Pour gÃ©nÃ©rer un rapport de couverture :

```bash
python run_tests.py --coverage
```

Le rapport HTML sera gÃ©nÃ©rÃ© dans `htmlcov/`.

## ğŸ›¡ï¸ Tests de sÃ©curitÃ©

Les tests de sÃ©curitÃ© vÃ©rifient :

1. **Validation des entrÃ©es** : Noms de projets, chemins, commandes
2. **PrÃ©vention d'injection** : Commandes dangereuses, caractÃ¨res spÃ©ciaux
3. **TraversÃ©e de rÃ©pertoires** : Chemins relatifs dangereux
4. **OpÃ©rations de fichiers** : Permissions, espace disque
5. **ExÃ©cution de scripts** : Validation des scripts avant exÃ©cution

## ğŸ”„ Workflow de dÃ©veloppement

### Ajouter un nouveau test

1. **Identifier le type** : unitaire ou intÃ©gration
2. **Choisir l'emplacement** : `tests/unit/` ou `tests/integration/`
3. **Nommer le fichier** : `test_<module>_<fonctionnalitÃ©>.py`
4. **Utiliser les fixtures** : RÃ©utiliser les fixtures existantes
5. **Ajouter les marqueurs** : Marquer avec les marqueurs appropriÃ©s

### Exemple de test unitaire

```python
import pytest
from shared.security_validator import SecurityValidator

class TestSecurityValidator:
    """Tests pour le validateur de sÃ©curitÃ©."""
    
    def test_validate_project_name_valid(self):
        """Test validation de nom de projet valide."""
        validator = SecurityValidator()
        is_valid, error = validator.validate_project_name("my-project")
        assert is_valid
        assert error == ""
    
    def test_validate_project_name_invalid(self):
        """Test validation de nom de projet invalide."""
        validator = SecurityValidator()
        is_valid, error = validator.validate_project_name("invalid;project")
        assert not is_valid
        assert "dangerous characters" in error
```

### Exemple de test d'intÃ©gration

```python
import pytest
from pathlib import Path

class TestProjectCreation:
    """Tests d'intÃ©gration pour la crÃ©ation de projets."""
    
    def test_create_python_project_structure(self, temp_dir):
        """Test que la crÃ©ation de projet Python gÃ©nÃ¨re la bonne structure."""
        project_name = "test-project"
        project_path = temp_dir / project_name
        
        # Simuler la crÃ©ation de projet
        project_path.mkdir()
        (project_path / "src").mkdir()
        (project_path / "tests").mkdir()
        
        # VÃ©rifier la structure
        assert project_path.exists()
        assert (project_path / "src").exists()
        assert (project_path / "tests").exists()
```

## ğŸ› DÃ©bogage des tests

### Mode debug

```bash
python run_tests.py --debug
```

### Tests spÃ©cifiques

```bash
# Test spÃ©cifique avec plus de dÃ©tails
pytest tests/unit/test_security_validator.py::TestSecurityValidator::test_validate_project_name_valid -v -s

# Tests avec Ã©chec uniquement
pytest --lf

# Tests avec Ã©chec et dÃ©pendances
pytest --lf --ff
```

### Logs et traces

```bash
# Afficher les logs
pytest --log-cli-level=DEBUG

# Traceback complet
pytest --tb=long

# ArrÃªter au premier Ã©chec
pytest -x
```

## ğŸ“ˆ MÃ©triques de qualitÃ©

### Couverture cible

- **Couverture globale** : â‰¥ 90%
- **Modules critiques** : â‰¥ 95% (sÃ©curitÃ©, CLI)
- **Nouvelles fonctionnalitÃ©s** : â‰¥ 95%

### Performance

- **Tests unitaires** : < 1 seconde par test
- **Tests d'intÃ©gration** : < 5 secondes par test
- **Suite complÃ¨te** : < 30 secondes

### FiabilitÃ©

- **Tests flaky** : 0%
- **Tests dÃ©pendants** : Ã‰viter les dÃ©pendances entre tests
- **Isolation** : Chaque test doit Ãªtre indÃ©pendant

## ğŸ” Bonnes pratiques

### Ã‰criture de tests

1. **Nommage clair** : Noms descriptifs pour les tests et classes
2. **Documentation** : Docstrings pour expliquer le but du test
3. **Arrange-Act-Assert** : Structure claire des tests
4. **Fixtures** : RÃ©utiliser les fixtures existantes
5. **Mocks appropriÃ©s** : Mocker les dÃ©pendances externes

### Maintenance

1. **Tests Ã  jour** : Maintenir les tests avec le code
2. **Refactoring** : Refactorer les tests quand nÃ©cessaire
3. **Performance** : Surveiller le temps d'exÃ©cution
4. **Couverture** : Maintenir une couverture Ã©levÃ©e

### IntÃ©gration continue

1. **ExÃ©cution automatique** : Tests sur chaque commit
2. **Rapports** : GÃ©nÃ©rer des rapports de couverture
3. **Seuils** : DÃ©finir des seuils de couverture
4. **Notifications** : Alerter en cas d'Ã©chec

## ğŸ†˜ DÃ©pannage

### ProblÃ¨mes courants

1. **Import errors** : VÃ©rifier le PYTHONPATH
2. **Fixtures manquantes** : VÃ©rifier conftest.py
3. **Tests lents** : Utiliser les marqueurs `@pytest.mark.slow`
4. **Tests flaky** : Ajouter des retries ou mocks

### Support

Pour les problÃ¨mes de tests :

1. VÃ©rifier la documentation pytest
2. Consulter les exemples existants
3. Utiliser le mode debug
4. VÃ©rifier les dÃ©pendances avec `--check-deps`